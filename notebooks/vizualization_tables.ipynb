{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a904f9",
   "metadata": {},
   "source": [
    "## Visualize benchmark results in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "999822a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import functools\n",
    "import pandas as pd\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from lm_polygraph.utils.manager import UEManager\n",
    "\n",
    "def b_g(s, A, cmap='PuBu', low=0.8, high=0):\n",
    "    # Pass the columns from Dataframe A\n",
    "    i = A.columns.tolist().index(s.name)\n",
    "    a = A.values[:,i].copy()\n",
    "    if s.name[-1] in ['rcc-auc']:\n",
    "        a = -a\n",
    "    if s.name[0] == 'BARTScoreSeq-rh':\n",
    "        a = -a\n",
    "    rng = a.max() - a.min()\n",
    "    norm = colors.Normalize(a.min() - (rng * low),\n",
    "                        a.max() + (rng * high))\n",
    "    normed = norm(a)\n",
    "    c = [colors.rgb2hex(x) for x in plt.colormaps[cmap](normed)]\n",
    "    return ['background-color: %s' % color for color in c]\n",
    "\n",
    "def get_array(dfs, row, col):\n",
    "    vals = []\n",
    "    for df in dfs:\n",
    "        if row in df.index and col in df.columns:\n",
    "            vals.append(df.loc[row, col])\n",
    "    return vals\n",
    "\n",
    "def pretty_plot(dataset_name, man_files, except_metrics=[], except_gen=['BARTScoreSeq-rh'], level='sequence'):\n",
    "    dfs = []\n",
    "    if isinstance(dataset_name, str):\n",
    "        dataset_name = [dataset_name]\n",
    "        man_files = [man_files]\n",
    "    columns = []\n",
    "    for group_name, group_files in zip(dataset_name, man_files):\n",
    "        gen_metrics = None\n",
    "        for f in group_files:\n",
    "            man = UEManager.load(f)\n",
    "            estimators = [e for (l, e) in man.estimations.keys() if l == level]\n",
    "            gen_metrics = list(set([(group_name, gen_name, m_name)\n",
    "               for (l, e_name, gen_name, m_name) in man.metrics\n",
    "               if l == level and (m_name not in except_metrics) and (gen_name not in except_gen)]))\n",
    "            gen_metrics.sort()\n",
    "            df = {k: {} for k in gen_metrics}\n",
    "            for (l, e_name, gen_name, m_name), value in man.metrics.items():\n",
    "                if l == level and (m_name not in except_metrics) and (gen_name not in except_gen):\n",
    "                    df[group_name, gen_name, m_name][e_name] = value\n",
    "            for k in gen_metrics:\n",
    "                df[k] = [df[k][e] for e in estimators]\n",
    "            df = pd.DataFrame(data=df, index=[e for e in estimators])\n",
    "            df = df.reindex(columns=gen_metrics)\n",
    "            dfs.append(df)\n",
    "        print('Will measure variance using', len(group_files), 'seeds')\n",
    "        columns += gen_metrics\n",
    "    assert(len(dfs) > 0)\n",
    "    index = dfs[0].index\n",
    "    mean, total = defaultdict(lambda: defaultdict(int)), defaultdict(lambda: defaultdict(int))\n",
    "    for col in columns:\n",
    "        for row in index:\n",
    "            \n",
    "            vals = get_array(dfs, row, col)\n",
    "\n",
    "\n",
    "            # NOTE: here we calculate the calibration score, but change to the normalized verison if needed.\n",
    "            vals = [vals[0]['calibration_score']]    \n",
    "            \n",
    "            # print(f\"DEBUG: row={row}, \\n col={col}, \\n vals={vals}, \\n type={type(vals)}\")  # Debug output\n",
    "            # print(f\"DEBUG: row={row}, \\n col={col}, \\n vals={vals}, \\n type={type(vals)}\")\n",
    "            \n",
    "            mean[row][col] = -np.mean(vals)\n",
    "            \n",
    "            total[row][col] = '{:.2f} ± {:.2f}'.format(np.mean(vals).item() * 100, np.std(vals).item() * 100)\n",
    "    \n",
    "    total_df = pd.DataFrame([[total[row][col] for col in columns] for row in index],\n",
    "                            index=index, columns=pd.MultiIndex.from_tuples(columns))\n",
    "    mean_df = pd.DataFrame([[mean[row][col] for col in columns] for row in index],\n",
    "                           index=index, columns=pd.MultiIndex.from_tuples(columns))\n",
    "    \n",
    "    s = total_df.style.apply(functools.partial(b_g, A=mean_df, cmap='Reds'), axis=0)\n",
    "    s.set_table_styles([{  # for row hover use <tr> instead of <td>\n",
    "        'selector': 'td:hover',\n",
    "        'props': [('background-color', '#ffffb3')]\n",
    "    }, {\n",
    "        'selector': '.index_name',\n",
    "        'props': 'font-style: italic; color: darkgrey; font-weight:normal;'\n",
    "    }])\n",
    "    s.set_table_styles({\n",
    "        columns[i]: [{'selector': 'th', 'props': 'border-left: {}px solid black'.format(1 if columns[i][0] == columns[i - 1][0] else 2)},\n",
    "                     {'selector': 'td', 'props': 'border-left: {}px solid black'.format(1 if columns[i][0] == columns[i - 1][0] else 2)}]\n",
    "        for i in range(1, len(columns)) if i == 0 or columns[i][1] != columns[i - 1][1]\n",
    "    }, overwrite=False, axis=0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31c03154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize results in a table\n",
    "# pretty_plot(\n",
    "#     'TriviaQA, Dolly3b',\n",
    "#     # outputs generated by scripts/polygraph_eval benchmark\n",
    "#     # provide several seeds to calculate variance\n",
    "#     ['./workdir/output_seed' + str(x)\n",
    "#      for x in range(1, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a1bfefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will measure variance using 1 seeds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yz926/.conda/envs/lmp/lib/python3.10/site-packages/lm_polygraph/utils/manager.py:462: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  res_dict = torch.load(load_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_722c5 td:hover {\n",
       "  background-color: #ffffb3;\n",
       "}\n",
       "#T_722c5 .index_name {\n",
       "  font-style: italic;\n",
       "  color: darkgrey;\n",
       "  font-weight: normal;\n",
       "}\n",
       "#T_722c5 th.col1 {\n",
       "  border-left: 1px solid black;\n",
       "}\n",
       "#T_722c5 td.col1 {\n",
       "  border-left: 1px solid black;\n",
       "}\n",
       "#T_722c5_row0_col0, #T_722c5_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "}\n",
       "#T_722c5_row1_col0, #T_722c5_row1_col1 {\n",
       "  background-color: #fb7c5c;\n",
       "}\n",
       "#T_722c5_row2_col0 {\n",
       "  background-color: #71020e;\n",
       "}\n",
       "#T_722c5_row2_col1 {\n",
       "  background-color: #a81016;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_722c5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_722c5_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Bloomz-COQA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_722c5_level1_col0\" class=\"col_heading level1 col0\" >Bert</th>\n",
       "      <th id=\"T_722c5_level1_col1\" class=\"col_heading level1 col1\" >Rouge_rougeL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level2\" >&nbsp;</th>\n",
       "      <th id=\"T_722c5_level2_col0\" class=\"col_heading level2 col0\" >ece</th>\n",
       "      <th id=\"T_722c5_level2_col1\" class=\"col_heading level2 col1\" >ece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_722c5_level0_row0\" class=\"row_heading level0 row0\" >SemanticEntropy</th>\n",
       "      <td id=\"T_722c5_row0_col0\" class=\"data row0 col0\" >90.00 ± 0.00</td>\n",
       "      <td id=\"T_722c5_row0_col1\" class=\"data row0 col1\" >70.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_722c5_level0_row1\" class=\"row_heading level0 row1\" >PTrue</th>\n",
       "      <td id=\"T_722c5_row1_col0\" class=\"data row1 col0\" >95.00 ± 0.00</td>\n",
       "      <td id=\"T_722c5_row1_col1\" class=\"data row1 col1\" >75.00 ± 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_722c5_level0_row2\" class=\"row_heading level0 row2\" >MaximumSequenceProbability</th>\n",
       "      <td id=\"T_722c5_row2_col0\" class=\"data row2 col0\" >90.20 ± 0.00</td>\n",
       "      <td id=\"T_722c5_row2_col1\" class=\"data row2 col1\" >71.21 ± 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14616456b0d0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize results in a table\n",
    "pretty_plot(\n",
    "    'Bloomz-COQA',\n",
    "    # outputs generated by scripts/polygraph_eval benchmark\n",
    "    # provide several seeds to calculate variance\n",
    "    ['../workdir/output/ue_manager_seed1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f9fa1c-7a23-4450-be9c-372023850e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_bounds.ipynb  result_tables.ipynb\n",
      "normalization.ipynb  vizualization_tables.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1fd0a3-d9dd-455c-b208-1cdeb11c50bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
