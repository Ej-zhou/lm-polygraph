{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6958a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from lm_polygraph.estimators import *\n",
    "from lm_polygraph.utils.model import WhiteboxModel\n",
    "from lm_polygraph.utils.dataset import Dataset\n",
    "from lm_polygraph.utils.processor import Logger\n",
    "from lm_polygraph.utils.manager import UEManager\n",
    "from lm_polygraph.ue_metrics import PredictionRejectionArea\n",
    "from lm_polygraph.generation_metrics import RougeMetric, BartScoreSeqMetric, ModelScoreSeqMetric, ModelScoreTokenwiseMetric, AggregatedMetric\n",
    "from lm_polygraph.utils.builder_enviroment_stat_calculator import (\n",
    "    BuilderEnvironmentStatCalculator\n",
    ")\n",
    "from lm_polygraph.defaults.register_default_stat_calculators import (\n",
    "    register_default_stat_calculators,\n",
    ")\n",
    "from lm_polygraph.utils.factory_stat_calculator import StatCalculatorContainer\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa507bf7-3f94-4fd4-beae-73bd4c93e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()  # Clears the GPU cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2919ad8e-e71d-46ac-aa48-2ea0f12a5150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a044bc3b6e24ce4b914a36098e10b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025e26e-fd7f-44b6-88d7-5876439a5ab0",
   "metadata": {},
   "source": [
    "# Specify HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7111f938-bc8c-4b82-82a1-fce490bc8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"meta-llama/Llama-2-7b-hf\"\n",
    "device = \"cuda\"\n",
    "model_type = \"Whitebox\"\n",
    "dataset_name = (\"LM-Polygraph/babi_qa\")\n",
    "batch_size = 1\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a3862-77d1-4bb4-8423-1f86f3a58b54",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7a7afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad32e49cb9a48c8996b68d01172b7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=device,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = WhiteboxModel(base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8136d360-eb55-4a27-8a21-b82b4a5e4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LLAMA\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe460bd5-35bb-4c36-a6b8-12b7a111b403",
   "metadata": {},
   "source": [
    "# Train and Eval Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0444bbb3-7b9d-4823-ad9b-2b2a217d1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use validation split, since test split of trivia_qa doesn't have reference answers\n",
    "dataset = Dataset.load(\n",
    "    dataset_name,\n",
    "    'input', 'output',\n",
    "    batch_size=batch_size,\n",
    "    prompt=\"Question: {question}\\nAnswer:{answer}\",\n",
    "    split=\"test\"\n",
    ")\n",
    "dataset.subsample(32, seed=seed)\n",
    "\n",
    "train_dataset = Dataset.load(\n",
    "    dataset_name,\n",
    "    'input', 'output',\n",
    "    batch_size=batch_size,\n",
    "    prompt=\"Question: {question}\\nAnswer:{answer}\",\n",
    "    split=\"train\"\n",
    ")\n",
    "# train_dataset.subsample(16, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61ed46-8757-4d83-baae-bf854bd11d0e",
   "metadata": {},
   "source": [
    "# Metric, UE Metric, and UE Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5baa618b-d6dc-4292-a316-30f0e0f8db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_methods = [MaximumSequenceProbability(), \n",
    "              SemanticEntropy(),\n",
    "              PTrue()\n",
    "              # MahalanobisDistanceSeq(\"decoder\"),\n",
    "             ]\n",
    "\n",
    "ue_metrics = [PredictionRejectionArea(), PredictionRejectionArea(max_rejection=0.5)]\n",
    "\n",
    "# Wrap generation metric in AggregatedMetric, since trivia_qa is a multi-reference dataset\n",
    "# (y is a list of possible correct answers)\n",
    "metrics = [AggregatedMetric(RougeMetric('rougeL'))]\n",
    "\n",
    "loggers = [Logger()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a992-fafe-46ce-ad38-77b1c77aa3df",
   "metadata": {},
   "source": [
    "# Stat Calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98d1f0f-320e-4d7b-97a9-fad63d0348e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingStatistic_config = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"text_column\": 'question',\n",
    "    \"label_column\": 'answer',\n",
    "    \"description\": '',\n",
    "    \"prompt\": \"Question: {question}\\nAnswer:\",\n",
    "    \"few_shot_split\": 'train',\n",
    "    \"train_split\": 'train',\n",
    "    \"load_from_disk\": False,\n",
    "    \"subsample_train_dataset\": 10,\n",
    "    \"n_shot\": 5,\n",
    "    \"train_dataset\": dataset_name,\n",
    "    \"train_test_split\": False,\n",
    "    \"background_train_dataset\": 'allenai/c4',\n",
    "    \"background_train_dataset_text_column\": 'text',\n",
    "    \"background_train_dataset_label_column\": 'url',\n",
    "    \"background_train_dataset_data_files\": 'en/c4-train.00000-of-01024.json.gz',\n",
    "    \"background_load_from_disk\": False,\n",
    "    \"subsample_background_train_dataset\": 10,\n",
    "    \"batch_size\": 1,\n",
    "    \"seed\": 1,\n",
    "    # \"size\" : 10,\n",
    "    # \"bg_size\" : 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b93cda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register default stat calculators\n",
    "result_stat_calculators = dict()\n",
    "scs = register_default_stat_calculators(model_type)\n",
    "for sc in scs:\n",
    "    result_stat_calculators[sc.name] = sc\n",
    "\n",
    "# register TrainingStatisticExtractionCalculator for the Mahalanobis Distance method\n",
    "result_stat_calculators.update(\n",
    "    {\n",
    "        \"TrainingStatisticExtractionCalculator\": StatCalculatorContainer(\n",
    "            name=\"TrainingStatisticExtractionCalculator\",\n",
    "            cfg=OmegaConf.create(TrainingStatistic_config),\n",
    "            stats=[\"train_embeddings\", \"background_train_embeddings\", \"train_greedy_log_likelihoods\"],\n",
    "            dependencies=[],\n",
    "            builder=\"lm_polygraph.defaults.stat_calculator_builders.default_TrainingStatisticExtractionCalculator\",\n",
    "        )\n",
    "    }\n",
    ")\n",
    "    \n",
    "builder_env_stat_calc = BuilderEnvironmentStatCalculator(model=model)\n",
    "available_stat_calculators = list(result_stat_calculators.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c0bc3-8278-4ede-a1f1-6bc3b071a644",
   "metadata": {},
   "source": [
    "# Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962fff25-5dae-4414-b406-9d4a657928f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "man = UEManager(\n",
    "    data=dataset,\n",
    "    model=model,\n",
    "    estimators=ue_methods,\n",
    "    builder_env_stat_calc=builder_env_stat_calc,\n",
    "    available_stat_calculators=available_stat_calculators,\n",
    "    generation_metrics=metrics,\n",
    "    ue_metrics=ue_metrics,\n",
    "    processors=loggers,\n",
    "    ignore_exceptions=False,\n",
    "    max_new_tokens=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a92e70-3036-430d-a60a-4c2ecf768d9d",
   "metadata": {},
   "source": [
    "# Compute Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7a129-cc59-4b55-b71f-fb4ee230a416",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/32 [00:00<?, ?it/s]\n",
      "  0%|                                                                                   | 0/32 [00:00<?, ?it/s]\u001b[AFrom v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n",
      "\n",
      "  3%|██▎                                                                        | 1/32 [00:08<04:15,  8.25s/it]\u001b[A\n",
      "  6%|████▋                                                                      | 2/32 [00:14<03:35,  7.18s/it]\u001b[A\n",
      "  9%|███████                                                                    | 3/32 [00:20<03:10,  6.58s/it]\u001b[A\n",
      " 12%|█████████▍                                                                 | 4/32 [00:26<03:01,  6.48s/it]\u001b[A\n",
      " 16%|███████████▋                                                               | 5/32 [00:33<02:58,  6.63s/it]\u001b[A\n",
      " 19%|██████████████                                                             | 6/32 [00:40<02:51,  6.59s/it]\u001b[A\n",
      " 22%|████████████████▍                                                          | 7/32 [00:46<02:38,  6.34s/it]\u001b[A\n",
      " 25%|██████████████████▊                                                        | 8/32 [00:52<02:32,  6.36s/it]\u001b[A\n",
      " 28%|█████████████████████                                                      | 9/32 [01:01<02:41,  7.03s/it]\u001b[A\n",
      " 31%|███████████████████████▏                                                  | 10/32 [01:09<02:41,  7.34s/it]\u001b[A\n",
      " 34%|█████████████████████████▍                                                | 11/32 [01:15<02:28,  7.08s/it]\u001b[A\n",
      " 38%|███████████████████████████▊                                              | 12/32 [01:22<02:17,  6.90s/it]\u001b[A\n",
      " 41%|██████████████████████████████                                            | 13/32 [01:28<02:09,  6.79s/it]\u001b[A\n",
      " 44%|████████████████████████████████▍                                         | 14/32 [01:35<02:00,  6.69s/it]\u001b[A\n",
      " 47%|██████████████████████████████████▋                                       | 15/32 [01:41<01:52,  6.62s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████                                     | 16/32 [01:48<01:48,  6.79s/it]\u001b[A\n",
      " 53%|███████████████████████████████████████▎                                  | 17/32 [01:54<01:36,  6.46s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "results = man()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6abce0-dba7-40c1-916f-1be546a78c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results.keys():\n",
    "    print(f\"UE Score: {key[1]}, Metric: {key[2]}, UE Metric: {key[3]}, Score: {results[key]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085161c-ac48-412a-af8a-89662d9a3462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f5a53-b5e9-430c-96d2-70cdc3d7cbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc7b22-0bf4-4748-8419-8e8f46c98a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28dbe58-f598-479c-ab7f-16689a40f9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
